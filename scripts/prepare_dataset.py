#!/usr/bin/env python3
"""
Script de transformation des donn√©es GEIPAN pour Hugging Face
Cr√©e un CSV d√©normalis√© optimis√© (1 ligne = 1 t√©moignage + infos du cas)
"""

import pandas as pd
import re
from pathlib import Path

# Chemins des fichiers
DATA_DIR = Path(__file__).parent.parent / "data"
INPUT_CAS = DATA_DIR / "export_cas_pub_20251127093552.csv"
INPUT_TEMOIGNAGES = DATA_DIR / "export_temoignages_pub_20251127093610.csv"
OUTPUT_CSV = DATA_DIR / "geipan_case_ovni_cleaned.csv"

# Headers pour le fichier cas (15 colonnes)
CAS_HEADERS = [
    "case_id",
    "titre_localisation",
    "date_observation",
    "departement",
    "region",
    "colonne_vide",  # Sera supprim√©e
    "zone_geographique",
    "resume_court",
    "reference_document",
    "description_detaillee",
    "notes_additionnelles",
    "info_additionnelle",
    "classification",
    "date_publication",
    "source"
]

def nettoyer_html(texte):
    """Remplace les balises HTML <br> par des espaces"""
    if pd.isna(texte):
        return texte
    texte = str(texte)
    # Remplace <br>, <br/>, <br />, <br<, etc. par un espace (y compris balises mal form√©es)
    texte = re.sub(r'<br\s*/?>|<br<', ' ', texte, flags=re.IGNORECASE)
    # Nettoie les espaces multiples
    texte = re.sub(r'\s+', ' ', texte)
    return texte.strip()

def charger_cas():
    """Charge et nettoie le fichier des cas"""
    print("üìÇ Chargement du fichier cas...")

    # Lecture avec pipe delimiter, skip blank line
    df_cas = pd.read_csv(
        INPUT_CAS,
        sep='|',
        header=None,
        names=CAS_HEADERS,
        skiprows=[0],  # Skip la premi√®re ligne vide
        encoding='utf-8',
        dtype=str,
        keep_default_na=False
    )

    print(f"   ‚úì {len(df_cas)} cas charg√©s")

    # Nettoie les case_id (trim espaces)
    df_cas['case_id'] = df_cas['case_id'].str.strip()

    # V√©rifie et supprime les doublons de case_id dans les cas
    duplicates_cas = df_cas['case_id'].duplicated().sum()
    if duplicates_cas > 0:
        print(f"   ‚ö†Ô∏è  {duplicates_cas} case_id en doublon d√©tect√©s, suppression...")
        df_cas = df_cas.drop_duplicates(subset=['case_id'], keep='first')
        print(f"   ‚úì {len(df_cas)} cas apr√®s suppression des doublons")

    # Supprime la colonne vide (col 5)
    df_cas = df_cas.drop(columns=['colonne_vide'])

    # Nettoie les balises HTML dans les descriptions
    print("üßπ Nettoyage des balises HTML...")
    df_cas['description_detaillee'] = df_cas['description_detaillee'].apply(nettoyer_html)
    df_cas['resume_court'] = df_cas['resume_court'].apply(nettoyer_html)
    df_cas['notes_additionnelles'] = df_cas['notes_additionnelles'].apply(nettoyer_html)

    # Nettoie les espaces en d√©but/fin
    for col in df_cas.columns:
        if df_cas[col].dtype == 'object':
            df_cas[col] = df_cas[col].str.strip()

    # Remplace les cha√Ænes vides par NaN
    df_cas = df_cas.replace('', pd.NA)

    return df_cas

def charger_temoignages():
    """Charge et nettoie le fichier des t√©moignages"""
    print("üìÇ Chargement du fichier t√©moignages...")

    # Lecture avec pipe delimiter, premi√®re ligne = headers
    df_temoignages = pd.read_csv(
        INPUT_TEMOIGNAGES,
        sep='|',
        encoding='utf-8',
        dtype=str,
        keep_default_na=False
    )

    print(f"   ‚úì {len(df_temoignages)} t√©moignages charg√©s")
    print(f"   ‚úì {len(df_temoignages.columns)} colonnes d√©tect√©es")

    # Renomme la premi√®re colonne en case_id pour le join
    df_temoignages.rename(columns={df_temoignages.columns[0]: 'case_id'}, inplace=True)

    # Nettoie les case_id (trim espaces)
    df_temoignages['case_id'] = df_temoignages['case_id'].str.strip()

    # V√©rifie les doublons dans les t√©moignages (devrait √™tre 0)
    duplicates_temoignages = df_temoignages.duplicated().sum()
    if duplicates_temoignages > 0:
        print(f"   ‚ö†Ô∏è  {duplicates_temoignages} t√©moignage(s) en doublon complet d√©tect√©(s), suppression...")
        df_temoignages = df_temoignages.drop_duplicates()
        print(f"   ‚úì {len(df_temoignages)} t√©moignages apr√®s suppression des doublons")

    # Supprime les colonnes avec >95% de valeurs vides
    print("üßπ Suppression des colonnes tr√®s sparse (>95% vides)...")
    threshold = len(df_temoignages) * 0.05  # Garde seulement si >5% rempli
    colonnes_avant = len(df_temoignages.columns)

    df_temoignages = df_temoignages.replace('', pd.NA)
    df_temoignages = df_temoignages.dropna(axis=1, thresh=threshold)

    colonnes_apres = len(df_temoignages.columns)
    print(f"   ‚úì {colonnes_avant - colonnes_apres} colonnes supprim√©es ({colonnes_apres} restantes)")

    # Nettoie les espaces
    for col in df_temoignages.columns:
        if df_temoignages[col].dtype == 'object':
            df_temoignages[col] = df_temoignages[col].str.strip()

    return df_temoignages

def joindre_donnees(df_cas, df_temoignages):
    """Joint les cas et t√©moignages (1 ligne = 1 t√©moignage)"""
    print("üîó Jointure cas + t√©moignages...")

    # Statistiques avant jointure
    nb_temoignages_input = len(df_temoignages)
    nb_cas_input = len(df_cas)
    print(f"   ‚Ä¢ {nb_temoignages_input:,} t√©moignages √† joindre")
    print(f"   ‚Ä¢ {nb_cas_input:,} cas disponibles")

    # Pr√©fixe les colonnes des cas pour √©viter les conflits
    colonnes_cas = [col if col == 'case_id' else f'cas_{col}' for col in df_cas.columns]
    df_cas.columns = colonnes_cas

    # V√©rifie s'il y a des doublons de case_id dans cas
    duplicates_cas_id = df_cas['case_id'].duplicated().sum()
    if duplicates_cas_id > 0:
        print(f"   ‚ö†Ô∏è  ATTENTION: {duplicates_cas_id} case_id en doublon dans le fichier cas!")

    # Left join depuis t√©moignages (tous les t√©moignages gard√©s)
    df_joined = df_temoignages.merge(
        df_cas,
        on='case_id',
        how='left'
    )

    print(f"   ‚úì {len(df_joined):,} lignes apr√®s jointure")

    # Si on a plus de lignes que de t√©moignages, c'est qu'il y a un probl√®me
    if len(df_joined) > nb_temoignages_input:
        diff = len(df_joined) - nb_temoignages_input
        print(f"   ‚ö†Ô∏è  +{diff} lignes cr√©√©es par la jointure (doublons de case_id dans fichier cas)")

    # Supprime les doublons exacts
    nb_avant = len(df_joined)
    df_joined = df_joined.drop_duplicates()
    nb_apres = len(df_joined)

    if nb_avant > nb_apres:
        print(f"   ‚úì {nb_avant - nb_apres} doublons exacts supprim√©s")

    print(f"   ‚úì {len(df_joined):,} lignes dans le dataset final")

    # R√©organise les colonnes : infos cas d'abord, puis t√©moignage
    colonnes_cas_prefixees = [col for col in df_joined.columns if col.startswith('cas_')]
    colonnes_temoignages = [col for col in df_joined.columns if not col.startswith('cas_') and col != 'case_id']

    colonnes_ordre = ['case_id'] + colonnes_cas_prefixees + colonnes_temoignages
    df_joined = df_joined[colonnes_ordre]

    return df_joined

def sauvegarder_csv(df, output_path):
    """Sauvegarde le DataFrame en CSV optimis√©"""
    print(f"üíæ Sauvegarde du CSV final...")

    # Sauvegarde avec pipe delimiter (coh√©rent avec l'original)
    df.to_csv(
        output_path,
        sep='|',
        index=False,
        encoding='utf-8',
        na_rep=''  # Valeurs manquantes = cha√Æne vide
    )

    # Stats du fichier
    file_size = output_path.stat().st_size / (1024 * 1024)  # MB
    print(f"   ‚úì Fichier cr√©√© : {output_path.name}")
    print(f"   ‚úì Taille : {file_size:.2f} MB")
    print(f"   ‚úì {len(df)} lignes √ó {len(df.columns)} colonnes")

def afficher_stats(df):
    """Affiche des statistiques sur le dataset"""
    print("\nüìä Statistiques du dataset final :")
    print(f"   ‚Ä¢ Total lignes : {len(df):,}")
    print(f"   ‚Ä¢ Total colonnes : {len(df.columns)}")
    print(f"   ‚Ä¢ Cas uniques : {df['case_id'].nunique():,}")
    print(f"   ‚Ä¢ T√©moignages par cas (moyenne) : {len(df) / df['case_id'].nunique():.2f}")

    # Distribution des classifications
    if 'cas_classification' in df.columns:
        print(f"\n   Classification des cas :")
        classif_counts = df.groupby('cas_classification')['case_id'].nunique()
        for classif, count in classif_counts.items():
            if classif:
                print(f"      - {classif} : {count:,} cas")

def main():
    print("=" * 60)
    print("üõ∏ GEIPAN Dataset Preparation pour Hugging Face")
    print("=" * 60)
    print()

    # 1. Charger les donn√©es
    df_cas = charger_cas()
    df_temoignages = charger_temoignages()

    print()

    # 2. Joindre les donn√©es
    df_final = joindre_donnees(df_cas, df_temoignages)

    print()

    # 3. Afficher les stats
    afficher_stats(df_final)

    print()

    # 4. Sauvegarder
    sauvegarder_csv(df_final, OUTPUT_CSV)

    print()
    print("=" * 60)
    print("‚úÖ Transformation termin√©e avec succ√®s !")
    print(f"üìÅ Fichier de sortie : {OUTPUT_CSV}")
    print("=" * 60)

if __name__ == "__main__":
    main()
