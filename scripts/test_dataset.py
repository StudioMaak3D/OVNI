#!/usr/bin/env python3
"""
Script de validation du dataset GEIPAN nettoy√©
V√©rifie la qualit√© des donn√©es, la jointure, et l'int√©grit√©
"""

import pandas as pd
from pathlib import Path

# Chemins
DATA_DIR = Path(__file__).parent.parent / "data"
CLEANED_CSV = DATA_DIR / "geipan_case_ovni_cleaned.csv"
ORIGINAL_CAS = DATA_DIR / "export_cas_pub_20251127093552.csv"
ORIGINAL_TEMOIGNAGES = DATA_DIR / "export_temoignages_pub_20251127093610.csv"

def test_fichier_existe():
    """V√©rifie que le fichier nettoy√© existe"""
    print("=" * 70)
    print("TEST 1 : Existence du fichier")
    print("=" * 70)

    if CLEANED_CSV.exists():
        file_size = CLEANED_CSV.stat().st_size / (1024 * 1024)
        print(f"‚úÖ Fichier trouv√© : {CLEANED_CSV.name}")
        print(f"   Taille : {file_size:.2f} MB")
        return True
    else:
        print(f"‚ùå Fichier non trouv√© : {CLEANED_CSV}")
        return False

def test_chargement():
    """Teste le chargement du CSV"""
    print("\n" + "=" * 70)
    print("TEST 2 : Chargement du CSV")
    print("=" * 70)

    try:
        df = pd.read_csv(CLEANED_CSV, sep='|', encoding='utf-8')
        print(f"‚úÖ CSV charg√© avec succ√®s")
        print(f"   Dimensions : {len(df):,} lignes √ó {len(df.columns)} colonnes")
        return df
    except Exception as e:
        print(f"‚ùå Erreur de chargement : {e}")
        return None

def test_structure(df):
    """V√©rifie la structure du dataset"""
    print("\n" + "=" * 70)
    print("TEST 3 : Structure des colonnes")
    print("=" * 70)

    # Colonnes obligatoires
    colonnes_requises = ['case_id', 'cas_titre_localisation', 'cas_classification',
                         'cas_date_observation', 'cas_region', 'cas_departement']

    manquantes = [col for col in colonnes_requises if col not in df.columns]

    if manquantes:
        print(f"‚ùå Colonnes manquantes : {manquantes}")
        return False
    else:
        print(f"‚úÖ Toutes les colonnes requises pr√©sentes")

    # Affiche les 20 premi√®res colonnes
    print(f"\n   Premi√®res colonnes :")
    for i, col in enumerate(df.columns[:20], 1):
        print(f"      {i:2d}. {col}")

    if len(df.columns) > 20:
        print(f"      ... et {len(df.columns) - 20} autres colonnes")

    return True

def test_jointure(df):
    """V√©rifie la qualit√© de la jointure"""
    print("\n" + "=" * 70)
    print("TEST 4 : Qualit√© de la jointure")
    print("=" * 70)

    # Charge les fichiers originaux
    df_cas_orig = pd.read_csv(ORIGINAL_CAS, sep='|', header=None, skiprows=[0], dtype=str)
    df_temoignages_orig = pd.read_csv(ORIGINAL_TEMOIGNAGES, sep='|', dtype=str)

    cas_orig_count = len(df_cas_orig)
    temoignages_orig_count = len(df_temoignages_orig)

    print(f"üìä Fichiers originaux :")
    print(f"   ‚Ä¢ {cas_orig_count:,} cas")
    print(f"   ‚Ä¢ {temoignages_orig_count:,} t√©moignages")

    print(f"\nüìä Dataset nettoy√© :")
    print(f"   ‚Ä¢ {len(df):,} lignes totales")
    print(f"   ‚Ä¢ {df['case_id'].nunique():,} cas uniques")

    # V√©rifie que tous les t√©moignages sont pr√©sents
    if len(df) < temoignages_orig_count:
        print(f"‚ö†Ô∏è  Attention : {temoignages_orig_count - len(df)} t√©moignages manquants")
    elif len(df) == temoignages_orig_count:
        print(f"‚úÖ Tous les t√©moignages pr√©sents")
    else:
        print(f"‚ö†Ô∏è  Plus de lignes que de t√©moignages originaux (+{len(df) - temoignages_orig_count})")

    # V√©rifie que toutes les lignes ont des infos de cas
    lignes_sans_cas = df[df['cas_titre_localisation'].isna() | (df['cas_titre_localisation'] == '')]

    if len(lignes_sans_cas) > 0:
        print(f"‚ùå {len(lignes_sans_cas)} lignes sans informations de cas (jointure √©chou√©e)")
        return False
    else:
        print(f"‚úÖ Toutes les lignes ont des informations de cas")

    # Distribution des t√©moignages par cas
    temoignages_par_cas = df.groupby('case_id').size()
    print(f"\nüìä Distribution t√©moignages/cas :")
    print(f"   ‚Ä¢ Minimum : {temoignages_par_cas.min()} t√©moignage(s)")
    print(f"   ‚Ä¢ Moyenne : {temoignages_par_cas.mean():.2f} t√©moignages")
    print(f"   ‚Ä¢ Maximum : {temoignages_par_cas.max()} t√©moignages")
    print(f"   ‚Ä¢ M√©diane : {temoignages_par_cas.median():.0f} t√©moignage(s)")

    return True

def test_nettoyage_html(df):
    """V√©rifie que les balises HTML ont √©t√© nettoy√©es"""
    print("\n" + "=" * 70)
    print("TEST 5 : Nettoyage des balises HTML")
    print("=" * 70)

    colonnes_texte = ['cas_description_detaillee', 'cas_resume_court', 'cas_notes_additionnelles']

    total_br = 0
    for col in colonnes_texte:
        if col in df.columns:
            br_count = df[col].astype(str).str.contains('<br', case=False, na=False).sum()
            total_br += br_count
            if br_count > 0:
                print(f"‚ö†Ô∏è  {br_count} balises <br> trouv√©es dans '{col}'")

    if total_br == 0:
        print(f"‚úÖ Aucune balise HTML <br> trouv√©e")
        return True
    else:
        print(f"‚ùå {total_br} balises HTML <br> restantes au total")
        return False

def test_colonnes_vides(df):
    """V√©rifie qu'il n'y a pas de colonnes 100% vides"""
    print("\n" + "=" * 70)
    print("TEST 6 : Colonnes vides")
    print("=" * 70)

    colonnes_vides = []
    for col in df.columns:
        if df[col].isna().all() or (df[col].astype(str).str.strip() == '').all():
            colonnes_vides.append(col)

    if colonnes_vides:
        print(f"‚ö†Ô∏è  {len(colonnes_vides)} colonne(s) enti√®rement vide(s) :")
        for col in colonnes_vides:
            print(f"      - {col}")
        return False
    else:
        print(f"‚úÖ Aucune colonne enti√®rement vide")
        return True

def test_classifications(df):
    """V√©rifie les classifications"""
    print("\n" + "=" * 70)
    print("TEST 7 : Classifications")
    print("=" * 70)

    if 'cas_classification' not in df.columns:
        print(f"‚ùå Colonne 'cas_classification' manquante")
        return False

    classif_counts = df.groupby('cas_classification')['case_id'].nunique().sort_index()

    print(f"üìä R√©partition des cas par classification :")
    for classif, count in classif_counts.items():
        if pd.notna(classif) and classif != '':
            print(f"   ‚Ä¢ {classif:4s} : {count:4,} cas")

    # V√©rifie les classifications valides
    classif_valides = {'A', 'B', 'C', 'D', 'D1', 'D2', 'NC'}
    classif_invalides = set(classif_counts.index) - classif_valides - {float('nan'), ''}

    if classif_invalides:
        print(f"‚ö†Ô∏è  Classifications non standards : {classif_invalides}")
    else:
        print(f"‚úÖ Toutes les classifications sont valides")

    return True

def test_echantillons(df):
    """Affiche quelques exemples de donn√©es"""
    print("\n" + "=" * 70)
    print("TEST 8 : Exemples de donn√©es")
    print("=" * 70)

    # Prend 3 cas au hasard
    cas_sample = df.groupby('case_id').first().sample(n=min(3, len(df)))

    for idx, (case_id, row) in enumerate(cas_sample.iterrows(), 1):
        nb_temoignages = len(df[df['case_id'] == case_id])
        print(f"\nüìù Exemple {idx} : {case_id}")
        print(f"   ‚Ä¢ Titre : {row['cas_titre_localisation'][:60]}...")
        print(f"   ‚Ä¢ Date : {row['cas_date_observation']}")
        print(f"   ‚Ä¢ R√©gion : {row['cas_region']}")
        print(f"   ‚Ä¢ Classification : {row['cas_classification']}")
        print(f"   ‚Ä¢ T√©moignages : {nb_temoignages}")
        if 'cas_resume_court' in row and pd.notna(row['cas_resume_court']):
            resume = str(row['cas_resume_court'])[:100]
            print(f"   ‚Ä¢ R√©sum√© : {resume}...")

def test_donnees_geographiques(df):
    """V√©rifie les donn√©es g√©ographiques"""
    print("\n" + "=" * 70)
    print("TEST 9 : Donn√©es g√©ographiques")
    print("=" * 70)

    # R√©gions
    if 'cas_region' in df.columns:
        nb_regions = df['cas_region'].nunique()
        print(f"‚úÖ {nb_regions} r√©gions uniques")

        top_regions = df.groupby('cas_region')['case_id'].nunique().sort_values(ascending=False).head(5)
        print(f"\n   Top 5 r√©gions par nombre de cas :")
        for region, count in top_regions.items():
            if pd.notna(region) and region != '':
                print(f"      ‚Ä¢ {region:30s} : {count:3,} cas")

    # D√©partements
    if 'cas_departement' in df.columns:
        nb_depts = df['cas_departement'].nunique()
        print(f"\n‚úÖ {nb_depts} d√©partements uniques")

def test_dates(df):
    """V√©rifie les dates"""
    print("\n" + "=" * 70)
    print("TEST 10 : Donn√©es temporelles")
    print("=" * 70)

    if 'cas_date_observation' not in df.columns:
        print(f"‚ùå Colonne de date manquante")
        return False

    # Parse les dates
    try:
        df['date_parsed'] = pd.to_datetime(df['cas_date_observation'], format='%d/%m/%Y', errors='coerce')

        date_min = df['date_parsed'].min()
        date_max = df['date_parsed'].max()

        print(f"‚úÖ P√©riode couverte :")
        print(f"   ‚Ä¢ Plus ancienne : {date_min.strftime('%d/%m/%Y')}")
        print(f"   ‚Ä¢ Plus r√©cente : {date_max.strftime('%d/%m/%Y')}")
        print(f"   ‚Ä¢ Dur√©e : {(date_max - date_min).days / 365.25:.1f} ann√©es")

        # Distribution par d√©cennie
        df['decade'] = (df['date_parsed'].dt.year // 10) * 10
        decade_counts = df.groupby('decade')['case_id'].nunique().sort_index()

        print(f"\n   Cas par d√©cennie :")
        for decade, count in decade_counts.tail(8).items():
            if pd.notna(decade):
                print(f"      ‚Ä¢ {int(decade)}s : {count:3,} cas")

        return True
    except Exception as e:
        print(f"‚ö†Ô∏è  Erreur de parsing des dates : {e}")
        return False

def main():
    print("\n")
    print("üß™ " + "=" * 66 + " üß™")
    print("   VALIDATION DU DATASET GEIPAN NETTOY√â")
    print("üß™ " + "=" * 66 + " üß™")
    print()

    tests_results = []

    # Test 1
    if not test_fichier_existe():
        print("\n‚ùå Tests arr√™t√©s : fichier non trouv√©")
        return

    # Test 2
    df = test_chargement()
    if df is None:
        print("\n‚ùå Tests arr√™t√©s : impossible de charger le fichier")
        return

    # Tests 3-10
    tests_results.append(("Structure", test_structure(df)))
    tests_results.append(("Jointure", test_jointure(df)))
    tests_results.append(("Nettoyage HTML", test_nettoyage_html(df)))
    tests_results.append(("Colonnes vides", test_colonnes_vides(df)))
    tests_results.append(("Classifications", test_classifications(df)))
    test_echantillons(df)
    test_donnees_geographiques(df)
    tests_results.append(("Dates", test_dates(df)))

    # R√©sum√©
    print("\n" + "=" * 70)
    print("üìä R√âSUM√â DES TESTS")
    print("=" * 70)

    passed = sum(1 for _, result in tests_results if result)
    total = len(tests_results)

    for test_name, result in tests_results:
        status = "‚úÖ" if result else "‚ùå"
        print(f"{status} {test_name}")

    print()
    print(f"Score : {passed}/{total} tests r√©ussis ({passed/total*100:.0f}%)")

    if passed == total:
        print("\nüéâ Tous les tests sont pass√©s ! Le dataset est pr√™t pour Hugging Face.")
    else:
        print(f"\n‚ö†Ô∏è  {total - passed} test(s) √©chou√©(s). V√©rifiez les erreurs ci-dessus.")

    print("\n" + "=" * 70 + "\n")

if __name__ == "__main__":
    main()
